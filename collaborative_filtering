import numpy as np
from scipy import spatial
import pandas as pd
from pandas.api.types import CategoricalDtype
from scipy.sparse import csr_matrix

DATASET_PATH_MOVIES_CSV = "C:/Users/Delta/PycharmProjects/MovieLens-Data-Analysis/data/movies.csv"
DATASET_PATH_RATINGS_CSV = "C:/Users/Delta/PycharmProjects/MovieLens-Data-Analysis/data/ratings_temp.csv"


def cosine_similarity(vec1, vec2, indexes):
    similarity_indexes = dict()
    for userId in indexes:
        ratings_per_userid = vec2[userId, :].ratings_for_movies_for_top_users()
        similarity_indexes[userId] = 1 - spatial.distance.cosine(vec1, ratings_per_userid)

    return similarity_indexes


def read_csv_file(file_path):
    return pd.read_csv(file_path, encoding="utf-8")


def delete_df_column(df, column):
    del df[column]
    return df


def chunks(list_to_chunk, n):
    # looping till length l
    for i in range(0, len(list_to_chunk), n):
        yield list_to_chunk[i:i + n]


def get_n_elements_dict(n, reversed_list, dict_to_sort):
    dict_sort = dict()
    if reversed_list:
        for key in list(reversed(list(dict_to_sort)))[0:n]:
            dict_sort[key] = dict_to_sort[key]
        return dict_sort

    for key in list(dict_to_sort)[0:n]:
        dict_sort[key] = dict_to_sort[key]

    return dict_sort


def preprocess_dataset():
    movies_df = read_csv_file(DATASET_PATH_MOVIES_CSV)
    ratings_df = read_csv_file(DATASET_PATH_RATINGS_CSV)

    movies_df = delete_df_column(movies_df, "genres")
    movie_id_title_dict = movies_df.set_index("movieId").T.to_dict("list")

    ratings_df = delete_df_column(ratings_df, "timestamp")

    users = list(ratings_df["userId"].unique())
    movies = list(ratings_df["movieId"].unique())
    ratings = list(ratings_df["rating"])
    rows = ratings_df["userId"].astype(CategoricalDtype(categories=users)).cat.codes
    cols = ratings_df["movieId"].astype(CategoricalDtype(categories=movies)).cat.codes

    user_item = csr_matrix((ratings, (rows, cols)), shape=(len(users), len(movies)))

    cols = ratings_df["userId"].astype(CategoricalDtype(categories=users)).cat.codes
    rows = ratings_df["movieId"].astype(CategoricalDtype(categories=movies)).cat.codes

    item_user = csr_matrix((ratings, (rows, cols)), shape=(len(movies), len(users)))

    userid_movies_with_ratings = ratings_df.groupby("userId").agg(
        {"movieId": lambda x: list(x), "rating": lambda x: list(x)})

    userId_indexes = userid_movies_with_ratings.axes[0]

    userid_movies_with_ratings["userId"] = list(userid_movies_with_ratings.axes[0])

    movies_rated_per_user = userid_movies_with_ratings[["userId", "movieId"]].copy()
    ratings_given_by_user_per_movie = userid_movies_with_ratings[["userId", "rating"]].copy()

    movies_rated_per_user_dict = movies_rated_per_user.set_index("userId").T.to_dict("list")
    ratings_given_by_user_per_movie_dict = ratings_given_by_user_per_movie.set_index("userId").T.to_dict("list")

    ratings_df.groupby("userId").agg({"movieId": lambda x: list(x), "rating": lambda x: list(x)})

    return movies_rated_per_user_dict, ratings_given_by_user_per_movie_dict, list(userId_indexes), users, \
           movie_id_title_dict, user_item, item_user


movies_rated_per_user_dict, ratings_given_by_user_per_movie_dict, userId_indexes, uniq_user_ids, \
movie_id_title_dict, user_item, item_user = preprocess_dataset()


def read_user_input(user_id_list):
    while True:
        try:
            collaborative_filtering_input = int(
                input("Please enter 0 for User-based, 1 for Item-based or 2 for Combination of the previous two: "))
            user_id_input = int(input("Give a User Id in order to present recommendations to that user: "))
        except ValueError:
            print('Please enter a valid number')

        if (collaborative_filtering_input in range(0, 2)) and (user_id_input in user_id_list):
            break
        else:
            print("Either the first choice is wrong or the user id does not exists, please try again")
    return collaborative_filtering_input, user_id_input


collaborative_filtering_input, user_id_input = read_user_input(uniq_user_ids)

if collaborative_filtering_input == 0:

    active_user_ratings = ratings_given_by_user_per_movie_dict[user_id_input]
    active_user_rated_movies = movies_rated_per_user_dict[user_id_input]

    list_of_chunks = list(chunks(userId_indexes, 100))
    rating_of_all_movies_active_user = user_item[user_id_input, :].ratings_for_movies_for_top_users()

    for chunk in list(list_of_chunks):

        # user_item_chunks = list()
        # for userId in chunk:
        #     user_item_chunks.append(user_item[userId, :].toarray())

        similar_users = cosine_similarity(rating_of_all_movies_active_user, user_item, chunk)

        twenty_closest_userIds = get_n_elements_dict(20, True, similar_users)
        top_twenty_user_ids = twenty_closest_userIds.keys()

        ratings_for_movies_for_top_users = user_item[top_twenty_user_ids, :].ratings_for_movies_for_top_users()

        sum_similarity_indexes = 0
        for _, value in similar_users.items():
            sum_similarity_indexes += value

        # multiply the similarity score with the ratings
        weighted_rating_matrix = similar_users

        sum_weighted_ratings_per_movie

        # by diving it with the sum of the similarity indexes
        normalized_sum_weighted_ratings_per_movie = sum_weighted_ratings_per_movie / sum_similarity_indexes

        # Create a DataFrame which displays top-n movie recommendations


elif collaborative_filtering_input == 1:

    # prepei na vroume tis tainies pou exei dosei rating o user -> rated
    # movie-movie similarity pou exei kanei rate me oles tis ipolipes pou uparxoun sto batch

    list_of_chunks = list(chunks(userId_indexes, 100))
    movies_active_user = item_user[user_id_input, :].ratings_for_movies_for_top_users()

    rated = np.array(np.where(user_movies[:, 0] > 0))

    for chunk in list(list_of_chunks):
        movies_active_user_chunks = movies_active_user[chunk]

    # Store indices of movies ra00ed by user

    N_final = []

    for _, batch in batches.split(item_user, movie_indices):
        X_batch, indices_batch = item_user[batch], movie_indices[batch]

        # Index and keep only the movies rated by the user that are inside the batch
        batch_dict = {o: i for i, o in enumerate(indices_batch)}
        rated_in_batch = np.intersect1d(rated[0, :], indices_batch).astype(int)
        rated_in_batch = np.array([batch_dict[x] for x in rated_in_batch])

        if (rated_in_batch.size == 0):
            continue

        # Compute movie-movie similarities
        sim_movies = cosine_similarity(X_batch[rated_in_batch, :], X_batch)

        # Find and store indices of most similar movies to the ones rated by user
        nearest_movies = np.array(np.where(sim_movies >= min_similarity_movies))
        N = indices_batch[nearest_movies[1, :]]
        N_final = np.concatenate((N_final, N), axis=0).astype(int)

    N_unique = np.unique(N_final)

    # Compute similarities between rated movies of user and all similar movies
    Sij = cosine_similarity(item_user[rated[0, :], :],
                            item_user[N_unique, :])

    # Compute predicted ratings for user
    pred_ratings = (Sij.T @ user_movies[rated, 0].T) / (np.sum(Sij.T, axis=1).reshape(-1, 1))
    pred_ratings_idx = np.vstack((pred_ratings[:, 0], N_unique)).T
    pred_top_n = pred_ratings_idx[pred_ratings_idx[:, 0].argsort()][::-1][:top_n_movies, :]

    # Create a DataFrame which displays top-n movie recommendations
    df = pd.DataFrame({'predicted_rating': pred_top_n[:, 0], 'index': pred_top_n[:, 1]})
    df['movieId'] = df['index'].apply(lambda x: idx_to_movieId.get(x))
    df['title'] = df['movieId'].apply(lambda x: titles_dict.get(x))
    df_item = df.drop(['index', 'movieId'], axis=1)

print('\nDisk-based collaborative filtering using the {} variant finished '
      'in {:.2f} s.\nThe data  were broken up into {} batches. \n'
      'Below are the top-{} recommended movies and corresponding ratings for user {}.\n'
      .format(task, dt, batches.get_n_splits(), top_n_movies, user_input))

# Hybrid collaborative filtering
if task == 'hybrid':
    df = df_item.append(df_user)
    df = df.sort_values(by='predicted_rating', ascending=False)[0:top_n_movies]
    print(df)
    # return df
